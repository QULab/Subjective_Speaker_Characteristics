---
title: "Linear models from voice descriptions to speaker characteristics"
author: "Laura Fernández Gallardo"
date: "December 2017"
output: 
  github_document:
    toc: true
    toc_depth: 3
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r echo=FALSE}

# clear
rm(list=ls())

```



```{r message=FALSE, warning=FALSE}

# Libraries needed:

library(RCurl) # to read raw data from repo
library(leaps) # for feature selection
library(knitr) # for kable

```

## Objectives

We are building simple linear regression models to relate speaker characteristics (SC) to voice descriptions (VD) items. SC are to be predicted given VD as descriptor.


## Loading data

Setting paths and loading subjective ratings from [listening tests](https://github.com/laufergall/Subjective_Speaker_Characteristics/tree/master/doc/listening_tests).


```{r echo=FALSE}

# setting paths and loading data

setwd("D:/Users/fernandez.laura/Documents/Work/Projects_Github/Subjective_Speaker_Characteristics/analysis/relationships_SC_VD")

path_github <- "https://raw.githubusercontent.com/laufergall/Subjective_Speaker_Characteristics/master/data/subjective_ratings"

sc <- read.csv(text=getURL(paste0(path_github,"/SC_ratings.csv")), header=TRUE, sep=",")  
vd <- read.csv(text=getURL(paste0(path_github,"/VD_ratings.csv")), header=TRUE, sep=",")  

```


From the SC data, pick only the speakers for which we have VD ratings.

```{r}

sc <- sc[sc$speaker_ID %in% unique(vd$speaker_ID),]

```


## Linear regression with caret


Descriptors are subjective ratings of voice descriptions, from 0 to 100. Hence, we do not pro-process with center + scaling.

Function to: 

* take input parameters (SC and VD of speakers of the same gender, 10 instances):
* prepare descriptors (address multicollinearity)
* fit linear model for each speaker characteristic - performing rfe
* output models' coefficients, r-squared and p-value of F-statistic for each lm fit



```{r}

fit.linearmodels <- function(sc_sub, vd_sub){
  
  # Our descriptors: VD ratings (from 0 to 100). Aggregate by speaker ID
  
  desc <- aggregate(vd_sub[,c(16:(16+33))], by = list(vd_sub$speaker_ID),mean)
  desc <- desc[,-1]
  
  # Center and scale descriptors
  # desc <- as.data.frame(lapply(desc, scale))
  
  # Out targets:  mean rating across listeners for each of the 34 SC 
  
  all.targets <- aggregate(sc_sub[,10:(10+33)], by = list(sc_sub$speaker_ID),mean, na.rm=T)
  all.targets <- all.targets[,-1]
  
  
  set.seed(2302)
  
  options(digits=2)
  
  all.lm <- lapply(all.targets, function(x){
    
    # finding the best descriptors (model selection)
    result.regsubsets <- leaps::regsubsets(desc,x)
    
    # we select the model with 2 descriptors
    selmodel <- summary(result.regsubsets)$which[2,]
    desc.selmodel <- names(selmodel[which(selmodel==TRUE)])[2:3]
    
    # fit the selected model and retrieve models' coefficients, descriptiors, r-squared, p-value of F-statistic
    
    fit <- lm(x ~ desc[,desc.selmodel[1]] + desc[,desc.selmodel[2]])
    
    f <- summary(fit)$fstatistic
    
    tmp <- coef(fit)
    tmp["r.squared"] <- summary(fit)$r.squared
    tmp["p.value"] <- pf(f[1],f[2],f[3],lower.tail=F)
    
    # build lm equation
    
    # rounded coefficients for better output
    cf <- round(coef(fit), 2) 
    
    # sign check to avoid having plus followed by minus for negative coefficients
    tmp["eq"] <- paste(cf[1],
                       ifelse(sign(cf[2])==1, "+", "-"), abs(cf[2]), desc.selmodel[1],
                       ifelse(sign(cf[3])==1, "+", "-"), abs(cf[3]), desc.selmodel[2])
    
    return(tmp)
  })
  
  return(all.lm)
  
}

```



### Predicting SC from VD of male speakers


They are 10 male speakers: 5 of the high WAAT class (warmth-attractiveness) and 5 of the low WAAT class.

```{r warning = FALSE}

# Select male speakers from dataframes SC and VD
sc_sub <- sc[sc$speaker_gender=='male',]
vd_sub <- vd[vd$speaker_gender=='m',]

# call our function and view the models' coefficients, r-squared and p-value of F-statistic
all.lm_males <- fit.linearmodels(sc_sub, vd_sub)


# create dataframe with the output of each model
all.lm_males <- data.frame(t(as.data.frame(all.lm_males)))

# view table
all.lm_males$r.squared <- as.numeric(as.matrix(all.lm_males$r.squared))
kable(all.lm_males[order(all.lm_males$r.squared, decreasing = T), c(6,4)])

```



### Predicting SC from VD of female speakers


They are 10 female speakers: 5 of the high WAAT class (warmth-attractiveness) and 5 of the low WAAT class.

```{r warning = FALSE}

# Select male speakers from dataframes SC and VD
sc_sub <- sc[sc$speaker_gender=='female',]
vd_sub <- vd[vd$speaker_gender=='w',]

# call our function and view the models' coefficients, r-squared and p-value of F-statistic
all.lm_females <- fit.linearmodels(sc_sub, vd_sub)

# create dataframe with the output of each model
all.lm_females <- data.frame(t(as.data.frame(all.lm_females)))

# view table
all.lm_females$r.squared <- as.numeric(as.matrix(all.lm_females$r.squared))
kable(all.lm_females[order(all.lm_females$r.squared, decreasing = T), c(6,4)])
```




## Conclusions

Following the Brunswik Lens Model revised by [1], the features that can be extracted from the speech signal (e.g. pitch and formant frequencies, speech tempo, etc.) can be seen as "Distal Cues", whereas the collected VC-subjective labels represent the "Proximal Percepts" that directly account for the final listeners' impressions of speakers (i.e. the SC dimensions). 

The [NSC](http://www.qu.tu-berlin.de/?id=nsc-corpus) data facilitates the research necessary to clarify the relationship between "Distal Cues" and "Proximal Percepts", which should lead to machines reaching the human performance in the attribution of speaker social characteristics.

In this script, we have built simple relationships between "Proximal Percepts" and speaker chatacteristics: items from the SC-Questionnaire (such as mitfühlend, intelligent, gelangweilt, etc.). Interestingly, r-squared is quite high. The next (and more tricky) step is to predict the "Proximal Percepts" from the "Distal Cues", that is, to build models able to predict voice description items (klanglos, melodisch, scharf, etc.) from measurable speeach features.

(See translations of the item names from German to English [here](https://github.com/laufergall/Subjective_Speaker_Characteristics/blob/master/doc/NSC-documentation_slides_v04.pdf), slides 15 and 18, or [here](https://github.com/laufergall/Subjective_Speaker_Characteristics/tree/master/data/subjective_ratings))
 
We should however highlight the main limitation of this study: we have only 20 voices labelled in terms of voice descriptions. More listening tests (such as [Listening Test 2](https://github.com/laufergall/Subjective_Speaker_Characteristics/tree/master/doc/listening_tests)) would be needed in order to collect more subjective ratings from the 300 NSC speakers.

[1] Scherer, K. R., "Personality Inference from Voice Quality: the Loud Voice of Extroversion," European Journal of Social Psychology, 8:467-487, 1978.